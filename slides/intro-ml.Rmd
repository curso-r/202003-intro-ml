---
title: "Introdução ao Machine Learning com R"
author: "<img src = 'https://d33wubrfki0l68.cloudfront.net/9b0699f18268059bdd2e5c21538a29eade7cbd2b/67e5c/img/logo/cursor1-5.png' width = '40%'>"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "custom.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
library(ggplot2)
library(magrittr)
library(tidyverse)
theme_set(theme_minimal(14))
options(htmltools.dir.version = FALSE)
```

## Sobre nós

<img src="img/professores.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>

---

# Programa do curso

- Introdução ao Machine Learning

- Estratégias gerais: separação da base de dados, reamostragem, tuning de modelos, métricas de performance

- Regressão linear, Regularização (LASSO e Ridge)

- Regressão logística, regressão vs classificação

- Árvores de Decisão

- Random Forest 

- Boosting - XGBoost

- Estudo de Caso

---

# Ciência de dados

<img src="img/ciclo-ciencia-de-dados.png" style = "display: block; margin-left: auto; margin-right: auto;">

---

# Referências

.pull-left[
<a href = "https://r4ds.had.co.nz/">
<img src="img/r4ds.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

.pull-right[
<a href = "http://www-bcf.usc.edu/~gareth/ISL/">
<img src="img/islr.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

---

class: middle, center, inverse

# Introdução

---

# O que é Machine Learning?

<br>


- Não é um termo novo: criado por Arthur Samuel, em 1959

<img src="img/arthur-sam.png" class="center2" width=100>


- Modelagem preditiva é um framework de análise de dados que visa gerar a estimativa mais precisa possível para uma quantidade ou fenômeno (Max Kuhn, 2014).


---

## Exemplos

<img src="https://user-images.githubusercontent.com/4706822/45316589-db1b4580-b50d-11e8-8e53-33950d5c4c07.jpg" style="position: fixed; width: 40%; top: 250px; left: 300px;">

--

<img src="http://pennachio.wpengine.com/wp-content/uploads/2017/02/diabetic-retinopathy_comparison-1024x469.jpg" style="position: fixed; width: 40%; top: 100px; left: 100px;">

--

<img src="https://www.extremetech.com/wp-content/uploads/2014/09/self-driving-head-640x353.jpg" style="position: fixed;  width: 40%; top: 100px; left: 500px;">

--

<img src="https://i2.wp.com/www.yaabot.com/wp-content/uploads/2016/11/yaabot_algo2.jpg?resize=759%2C500&ssl=1" style="position: fixed; width: 40%; top: 400px; left: 500px;">

--

<img src="https://5.imimg.com/data5/NT/NK/MY-38742550/life-insurance-health-insurance-and-general-insurance-250x250.png" style="position: fixed; width: 20%; top: 200px; left: 100px;">


---

<img src="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?Q_SmWhhhAEOO_32HNjPhcxsPhreWV26o&itok=yjEJbEKD" style="display: block; margin-left: auto; margin-right: auto;"></img>

---

# Motivação

```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE,
  fig.width=6, 
  fig.height=6,
  fig.align='center'
)
library(rpart)
adv <- read_csv("data/Advertising.csv")
```

Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok <- adv %>% 
  gather(midia, investimento, -sales)

adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Motivação


Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Machine Learning 

Matematicamente, queremos encontrar uma função $f()$ tal que:

<img src="img/y_fx.png" style="position: fixed; width: 40%; top: 250px; left: 300px;">



---

# Exemplos de $f(x)$

```{r, fig.width = 12, fig.height = 5}
adv_ok <- adv %>% 
  gather(midia, investimento, -sales)

arvore <- rpart::rpart(sales ~ investimento + midia, data = adv_ok)
regressao_linear <- lm(sales ~ investimento + midia, data = adv_ok)
adv_ok <- adv_ok %>%
  mutate(
    arvore = predict(arvore, newdata = .),
    regressao_linear = predict(regressao_linear, newdata = .),
  )
grafico_sem_curva <- adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  facet_wrap(~midia, scales = "free") +
  labs(colour = "f(x):") +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 22),
        legend.title = element_text(size = 30))

grafico_curva_arvore <- grafico_sem_curva +
  geom_line(aes(y = arvore, colour = "Árvore de Decisão"), size = 2)
```

```{r, fig.width = 12, fig.height = 5}
grafico_sem_curva + 
  geom_step(aes(y = regressao_linear, colour = "Regressão Linear"), size = 2)
```

---

# Exemplos de $f(x)$

```{r, fig.width = 12, fig.height = 5}
grafico_curva_arvore
```

---

# Flexibilidade ou Interpretabilidade da f(x)

```{r}
#![](https://user-images.githubusercontent.com/4706822/47456108-01d5c880-d7aa-11e8-899a-74804f74afc5.png)
```

```{r, fig.width=11, fig.height=7}
library(ggrepel)
set.seed(1)
tribble(
  ~modelo, ~Flexibilidade, ~Interpretabilidade,
  "Regressão Linear", 0, 3,
  "Regressão Logística", 0, 3, 
  "LASSO", 0.3, 2.7,
  "Árvore de Decisão", 1, 2.2,
  "Generalized Additive Models", 1.5, 1.5,
  "Redes Neurais, Deep Learning", 3, 1,
  "Bagging, Boosting", 3.2, 0.8,
  "SVM", 2.6, 0.5
) %>%
  ggplot(aes(x = Flexibilidade, y = Interpretabilidade)) +
  geom_text_repel(aes(label = modelo), size = 7) +
  theme_minimal(24) +
  scale_x_continuous(breaks = c(0, 3.2), labels = c("Baixo", "Alto")) +
  scale_y_continuous(breaks = c(0, 3.5), labels = c("Baixo", "Alto"))


```



---

# Definições e Nomenclaturas

* $X_1$, $X_2$, ..., $X_p$: variáveis explicativas (ou variáveis independentes ou *features* ou preditores).

- $\boldsymbol{X} = {X_1, X_2, \dots, X_p}$: conjunto de todas as *features*.

* __Y__: variável resposta (ou variável dependente ou *target*). 
* __Ŷ__: valor **esperado** (ou predição ou estimado ou *fitted*). 
* $f(X)$ também é conhecida também como "Modelo" ou "Hipótese".

## No exemplo:

- $X_1$: `midia` - indicadador de se a propaganda é para jornal, rádio, ou TV.
- $X_2$: `investimento` - valor do orçamento

* __Y__: `sales` - qtd vendida


---

# Definições e Nomenclaturas

## Observado VERSUS Esperado

- __Y__ é um valor **observado** (ou verdade ou *truth*)
- __Ŷ__ é um valor **esperado** (ou predição ou estimado ou *fitted*). 
- __Y__ - __Ŷ__ é o resíduo (ou erro)

Por definição, $\hat{Y} = f(x)$ que é o valor que a função $f$ retorna. 

```{r, fig.width = 12, fig.height = 5}
ponto_predito = tibble::tribble(
   ~investimento,   ~yend, ~midia,
             150,    0, "TV",
              35,    0, "radio",
              60,    0, "newspaper"
) %>%
  mutate(
    sales = predict(arvore, .)
  )

grafico_curva_arvore +
  geom_segment(aes(xend = investimento, yend = yend), data = ponto_predito, colour = "purple", size = 1, linetype = "dashed") +
  geom_segment(aes(xend = 0, yend = sales), data = ponto_predito, colour = "purple", size = 1, linetype = "dashed") +
  geom_point(data = ponto_predito, colour = "purple", size = 5) +
  theme_minimal(20)  +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 22),
        legend.title = element_text(size = 30))
```


---

# Por que ajustar uma f?

* Predição
* Inferência

## Predição

Em muitas situações X está disponível facilmente mas, Y não é fácil de descobrir. (Ou mesmo não é possível descobrí-lo).

$$\hat{Y} = \hat{f}(X)$$
é uma boa estimativa.
Neste caso não estamos interessados em como é a estrutura $\hat{f}$ desde que ela apresente predições boas para $Y$.

---

# Por que estimar f?

* Predição
* Inferência

## Inferência

Em inferência estamos mais interessados em entender a relação entre as variáveis explciativas $X$ e a variável resposta $Y$.

Por exemplo:

* Quais são as variáveis que estão mais relacionadas com a respostas?
* Qual a relação entre a resposta e cada um dos preditores?


Neste curso, vamos falar principalmente sobre **predição**.


---

# Modo - Regressão e Classificação

Existem dois principais tipos de problemas em Machine Learning:

.pull-left[

## Regressão

__Y__ é uma variável contínua.

- Volume de vendas
- Peso
- Temperatura
- Valor de Ações

]

.pull-right[

## Classificação

__Y__ é uma variável categórica.

- Fraude/Não Fraude
- Pegou em dia/Não pagou
- Cancelou assinatura/Não cancelou (churn)
- Gato/Cachorro/Cavalo/Outro



]



---

# Ir p/ R



---


# Métricas

Métricas: para medir o quanto a $f(x)$ está errando as previsões.

.pull-left[

## Regressão

__Y__ é uma variável contínua.

- RMSE
- R2
- MAE
- MAPE
...
]

.pull-right[

## Classificação

__Y__ é uma variável categórica.

- Acurácia
- AUROC
- Precision/Recall
- Deviance (Cross-Entropy)
- F1
- Kappa
...
]

[lista de métricas no `yardstick`](https://tidymodels.github.io/yardstick/articles/metric-types.html)

---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$

Ou seja, nosso **objetivo** é

## Encontrar $f(x)$ que nos retorne o ~menor~ RMSE.

```
Exercício mental: encontre a expressão dos resíduos na fórmula.
```

---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$

```{r, fig.width=10, fig.height=4, warning=FALSE}
melhor_reta <- lm(dist ~ speed, data = cars)
cars_com_predicoes <- melhor_reta %>% 
  broom::augment() %>%
  rename(pred_melhor_reta = .fitted) %>%
  mutate(
    pred_reta_a_mao = 12 + 3 * speed
  )

grafico_residuos_melhor_reta <- cars_com_predicoes %>%
  ggplot(aes(x = speed, y = dist)) +
  geom_point(size = 2) +
  geom_abline(
    intercept = melhor_reta$coefficients[1], 
    slope =     melhor_reta$coefficients[2], 
    size = 1,
    colour = "salmon"
  ) +
  geom_segment(aes(xend = speed, yend = pred_melhor_reta), colour = "blue", size = 1) +
  labs(
    subtitle = "Resíduos da Melhor Reta",
    title = "Os segmentos azuis são os resíduos (ou o quanto o modelo errou naqueles pontos)."
  ) 

grafico_residuos_reta_a_mao <- cars_com_predicoes %>%
  ggplot(aes(x = speed, y = dist)) +
  geom_point(size = 2) +
  geom_abline(
    intercept = 12, 
    slope =     3, 
    size = 1,
    colour = "orange"
  ) +
  geom_segment(aes(xend = speed, yend = pred_reta_a_mao), colour = "blue", size = 1) +
  labs(
    subtitle = "Resíduos da Reta Escolhida a Mão"
  ) 
library(patchwork)
grafico_residuos_melhor_reta + grafico_residuos_reta_a_mao
```

---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$


.pull-left[

MAE: Mean Absolute Error

$$
MAE = \frac{1}{N}\sum|y_i - \hat{y_i}|
$$

]

.pull-right[

R2: R-squared

$$
R^2 = 1 - \frac{\sum(y_i - \color{salmon}{\hat{y_i}})^2}{\sum(y_i - \color{royalblue}{\bar{y}})^2}
$$
]


---

# Ir para o R

---

# Overfitting (sobreajuste)

Intuição

![scatter_eqm](img/overfiting_scatter_eqm.gif)

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]



---

# Dados novos vs antigos

- **Base de Treino** (dados antigos): a base de histórico que usamos para ajustar o modelo.

- **Base de Teste** (dados novos): a base que irá simular a chegada de dados novos, "em produção".

.pull-left[

```{r, eval = FALSE, echo=TRUE}
initial_split(dados, prop=3/4)
```


> "Quanto mais complexo for o modelo, menor será o **erro de treino.**"

> "Porém, o que importa é o **erro de teste**."

]

.pull-right[
<img src="img/erro_treino_erro_teste.png" width = "500px">

]

---

# Dados novos vs antigos

## Estratégia


### 1) Separar inicialmente a base de dados em duas: treino e teste.

```{r, eval = FALSE, echo=TRUE}
initial_split(dados, prop=3/4) # 3/4 da base será de treino
```

A base de teste que só será tocada quando a modelagem terminar. Ela nunca deverá influenciar as decisões que tomamos no período da modelagem.

### 2) Criar bases de reamostragem na base de treino para "estimar" o erro de teste.

```{r, eval = FALSE, echo=TRUE}

mc_cv(dados_treino)
vfold_cv(dados_treino) # cross-validation: a mais popular.
bootstraps(dados_treino)
# etc.
```


---

# Hiperparâmetros

São parâmetros que têm que ser definidos antes de ajustar o modelo. Não há como achar o valor ótimo diretamente nas funções de custo. Precisam ser achados "na força bruta".

Exemplo: `min_n` das árvores


.pull-left[

```
decision_tree(min_n = 100)
```

]

.pull-right[

```{r}

arvore <- rpart::rpart(sales ~ investimento + midia, data = adv_ok, control = rpart.control(minbucket = 100))
arvore %>% rpart.plot::rpart.plot(type = 2, extra = 1)
```


]


---

# Hiperparâmetros

São parâmetros que têm que ser definidos antes de ajustar o modelo. Não há como achar o valor ótimo diretamente nas funções de custo. Precisam ser achados "na força bruta".

Exemplo: `min_n` das árvores


.pull-left[

```
decision_tree(min_n = 5)
```



]

.pull-right[

```{r}

arvore <- rpart::rpart(sales ~ investimento + midia, data = adv_ok, control = rpart.control(minbucket = 5))
arvore %>% rpart.plot::rpart.plot(type = 2, extra = 1)
```

]

---

class: inverse
background-image: url(img/ml_101.png)
background-position: left 145px
background-size: contain

# Resumo dos conceitos



